Prosody Analysis Module (AI Interview Coach)

ì´ ì €ì¥ì†ŒëŠ” ë©´ì ‘ ì˜ìƒ ë° ìŒì„± ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë°œí™”ìì˜ìŒì„± íŠ¹ì§•(Prosody)ì„ ì¶”ì¶œí•˜ê³ ,
ë©´ì ‘ ì—­ëŸ‰ ì ìˆ˜(Overall, Hiring)ë¥¼ ì‚°ì¶œí•˜ëŠ” Python ëª¨ë“ˆì…ë‹ˆë‹¤.

Praat(Parselmouth) ì—”ì§„ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ì— ìµœì í™”ëœ 4ëŒ€ í•µì‹¬ Feature[F1ëŒ€ì—­í­, í‰ê· ë©ˆì¶¤ê¸¸ì´, ë¬´ì„±ìŒë¹„ìœ¨, í‰ê· ê°•ë„] ë¶„ì„ì„ ê¸°ë³¸ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.

ğŸ“‚ íŒŒì¼ êµ¬ì¡° (File Structure)
Plaintext

P_prosody/

â”œâ”€â”€ prosody_analysis.py             # [ë©”ì¸] ê³ ì† ë¶„ì„ ëª¨ë“ˆ (Core 4 Features)

â””â”€â”€ requirements.txt                # ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ëª©ë¡

ğŸ› ï¸ ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì • (Installation)

1. Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
Bash
pip install -r requirements.txt

3. FFmpeg ì„¤ì¹˜ (í•„ìˆ˜ â­)
ì´ ëª¨ë“ˆì€ ë¯¸ë””ì–´ ë³€í™˜ì„ ìœ„í•´ ì‹œìŠ¤í…œì˜ FFmpegë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤. ë”°ë¼ì„œ OSì— FFmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆê³ , í™˜ê²½ ë³€ìˆ˜(PATH)ì— ë“±ë¡ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

Windows: ffmpeg.orgì—ì„œ ë‹¤ìš´ë¡œë“œ í›„ bin í´ë”ë¥¼ ì‹œìŠ¤í…œ í™˜ê²½ ë³€ìˆ˜ Pathì— ì¶”ê°€.

Mac: brew install ffmpeg

Linux: sudo apt install ffmpeg

í™•ì¸ ë°©ë²•: í„°ë¯¸ë„ì— ffmpeg -versionì„ ì…ë ¥í–ˆì„ ë•Œ ë²„ì „ ì •ë³´ê°€ ë‚˜ì™€ì•¼ í•©ë‹ˆë‹¤.


ğŸš€ ì‚¬ìš© ë°©ë²• (Usage)

## ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from prosody_analysis import ProsodyAnalyzerLight

# 1. ë¶„ì„ê¸° ì´ˆê¸°í™”
analyzer = ProsodyAnalyzerLight()

# 2. íŒŒì¼ ë¶„ì„ (ì˜ìƒ ë˜ëŠ” ìŒì„± íŒŒì¼ ê²½ë¡œ)
input_file = "user_upload/interview.mp4"
success = analyzer.analyze(input_file)

# 3. ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (í”„ë¡œí¼í‹°ë¡œ ì ‘ê·¼)
if success:
    print(f"ì„±ë³„: {analyzer.gender}")
    print(f"í‰ê·  í”¼ì¹˜: {analyzer.mean_pitch}Hz")
    print(f"F1 ëŒ€ì—­í­: {analyzer.avg_band1}Hz")
    print(f"í‰ê·  ê°•ë„: {analyzer.intensity_mean}dB")
    print(f"ë¬´ì„±ìŒ ë¹„ìœ¨: {analyzer.percent_unvoiced}")
    print(f"í‰ê·  íœ´ì§€ ì‹œê°„: {analyzer.avg_dur_pause}s")
    print(f"ì¢…í•© ì ìˆ˜: {analyzer.scores['Overall']}")
    print(f"ê³ ìš© ì¶”ì²œ ì ìˆ˜: {analyzer.scores['RecommendedHiring']}")
else:
    print("ë¶„ì„ ì‹¤íŒ¨ (íŒŒì¼ ì†ìƒ ë˜ëŠ” FFmpeg ì˜¤ë¥˜)")
```

## ì‹œê°í™” (Z-Score ë¶„í¬ ê·¸ë˜í”„)

```python
# Figure ê°ì²´ë¡œ ë°›ê¸°
fig = analyzer.get_zscore_visualization()
fig.savefig("output.png")

# ë˜ëŠ” ì§ì ‘ íŒŒì¼ë¡œ ì €ì¥
analyzer.get_zscore_visualization(save_path="output.png")

# ë˜ëŠ” ì´ë¯¸ì§€ ë°”ì´íŠ¸(PNG)ë¡œ ë°›ê¸°
img_bytes = analyzer.get_zscore_visualization(return_bytes=True)
with open("output.png", "wb") as f:
    f.write(img_bytes)
```
    
# all feature ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°
ëª¨ë“  ìŒí–¥ ì§€í‘œ(Shimmer, Jitter, Formant Ratio ë“±)ê°€ í•„ìš”í•œ ê²½ìš° prosody_analysis_all_feature ëª¨ë“ˆì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
from prosody_analysis_all_feature import ProsodyAnalyzer

analyzer = ProsodyAnalyzer()
result = analyzer.analyze("interview.mp4")
```

ì‚¬ìš©ë²•ì€ `ProsodyAnalyzerLight`ì™€ ë™ì¼í•©ë‹ˆë‹¤.

# analyzeë©”ì„œë“œ ë°˜í™˜í˜•íƒœ 

**ë³€ê²½ë¨**: `analyze()` ë©”ì„œë“œëŠ” ë” ì´ìƒ JSON ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  ë¶„ì„ ìˆ˜í–‰ ì—¬ë¶€(True/False)ë¥¼ ë°˜í™˜í•˜ê³ , ë¶„ì„ ê²°ê³¼ëŠ” **ë©¤ë²„ë³€ìˆ˜ í”„ë¡œí¼í‹°**ë¡œ ì œê³µí•©ë‹ˆë‹¤.

| í”„ë¡œí¼í‹° | ë°˜í™˜í˜• | ì„¤ëª… |
|---------|--------|------|
| `gender` | str | ìë™ ê°ì§€ëœ ì„±ë³„ ("Male" \| "Female") |
| `mean_pitch` | float | ì„±ë³„ ê°ì§€ ê¸°ì¤€ì´ ëœ í‰ê·  í”¼ì¹˜ (Hz) |
| `avg_band1` | float | F1 ëŒ€ì—­í­ (Hz) - ëª©ì†Œë¦¬ ëª…ë£Œë„/ê³µëª… |
| `intensity_mean` | float | í‰ê·  ê°•ë„ (dB) |
| `percent_unvoiced` | float | ë¬´ì„±ìŒ ë¹„ìœ¨ (0.0 ~ 1.0) |
| `avg_dur_pause` | float | í‰ê·  íœ´ì§€ ì‹œê°„ (sec) |
| `scores` | dict | ë¶„ì„ ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ {"Overall": float, "RecommendedHiring": float} |

```python
# ì‚¬ìš© ì˜ˆì‹œ
analyzer = ProsodyAnalyzerLight()
if analyzer.analyze("audio.wav"):
    print(analyzer.gender)
    print(analyzer.scores)
else:
    print("ë¶„ì„ ì‹¤íŒ¨")
```

## ì£¼ìš” ë©”ì„œë“œ

### 1. `analyze(file_path)` 
ìŒì„±/ì˜ìƒ íŒŒì¼ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ë©¤ë²„ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `file_path` (str): ë¶„ì„í•  ë¯¸ë””ì–´ íŒŒì¼ ê²½ë¡œ

**ë°˜í™˜ê°’:**
- `True`: ë¶„ì„ ì„±ê³µ
- `False`: ë¶„ì„ ì‹¤íŒ¨

**ì‚¬ìš© ì˜ˆ:**
```python
success = analyzer.analyze("interview.mp4")
```

### 2. `get_zscore_visualization(save_path=None, return_bytes=False)`
ê° featureë³„ Z-scoreë¥¼ ì •ê·œë¶„í¬ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `save_path` (str, optional): ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ (PNG)
- `return_bytes` (bool): `True`ë©´ PNG ë°”ì´íŠ¸ ë°˜í™˜, `False`ë©´ Figure ê°ì²´ ë°˜í™˜

**ë°˜í™˜ê°’:**
- `return_bytes=False`: matplotlib `Figure` ê°ì²´
- `return_bytes=True`: PNG ì´ë¯¸ì§€ ë°”ì´íŠ¸

**ì‚¬ìš© ì˜ˆ:**
```python
# 1. Figure ê°ì²´ë¡œ ë°›ì•„ í‘œì‹œ
fig = analyzer.get_zscore_visualization()
plt.show()

# 2. íŒŒì¼ë¡œ ì§ì ‘ ì €ì¥
analyzer.get_zscore_visualization(save_path="chart.png")

# 3. ë°”ì´íŠ¸ë¡œ ë°›ì•„ ì²˜ë¦¬ (ì›¹ ì„œë²„ ë“±ì—ì„œ í™œìš©)
img_bytes = analyzer.get_zscore_visualization(return_bytes=True)
```

## ë¶„ì„ ë¡œì§ ìƒì„¸ (Technical Details)

ë³¸ ëª¨ë“ˆì€ ì¼ê´€ì„± ìˆëŠ” ë¶„ì„ ê²°ê³¼ë¥¼ ìœ„í•´ ì „ì²˜ë¦¬(Normalization) â†’ íŠ¹ì§• ì¶”ì¶œ â†’ ì„±ë³„ ê°ì§€ â†’ ì ìˆ˜ ì‚°ì¶œì˜ íŒŒì´í”„ë¼ì¸ì„ ë”°ë¦…ë‹ˆë‹¤.

## 1. ì „ì²˜ë¦¬ (Preprocessing)
ë…¹ìŒ í™˜ê²½(ë§ˆì´í¬ ê±°ë¦¬, ì…ë ¥ ê²Œì¸)ì— ë”°ë¥¸ í¸ì°¨ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ ë¶„ì„ ì „ ì˜¤ë””ì˜¤ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.
* **Peak Normalization (-1dB):** ì…ë ¥ëœ ì˜¤ë””ì˜¤ì˜ ìµœëŒ€ ì§„í­ì„ **-1dB (ì•½ 0.89)**ë¡œ í†µì¼í•©ë‹ˆë‹¤.
* **íš¨ê³¼:** * ì‘ê²Œ ë…¹ìŒëœ ëª©ì†Œë¦¬ë„ í‘œì¤€ í¬ê¸°ë¡œ ë³´ì •ë¨
  
### 2. ë¶„ì„ Feature (Light Version)
ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜•ì„ ìœ„í•´ ë‹¤ìŒ 4ê°€ì§€ í•µì‹¬ ì§€í‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
* **F1 Bandwidth:** ëª©ì†Œë¦¬ì˜ ê³µëª…ê³¼ ëª…ë£Œë„ë¥¼ ì¸¡ì • (Formant ë¶„ì„).
* **Mean Intensity:** ëª©ì†Œë¦¬ì˜ í¬ê¸° ë° ì—ë„ˆì§€ (Normalization ì´í›„ì˜ ë°€ë„ ì¸¡ì •).
* **Unvoiced Rate:** ìˆœìˆ˜ ë°œí™” ì‹œê°„ ì¤‘ ì„±ëŒ€ê°€ ìš¸ë¦¬ì§€ ì•ŠëŠ”(ë¬´ì„±ìŒ) êµ¬ê°„ì˜ ë¹„ìœ¨.
* **Mean Pause Duration:** ë°œí™” ì‚¬ì´ì˜ ì¹¨ë¬µ ê¸¸ì´ (ê´€ë ¨ ì—°êµ¬ ë…¼ë¬¸ì— ê¸°ë°˜í•˜ì—¬ **0.5ì´ˆ ì´ìƒ** ì§€ì†ëœ ì¹¨ë¬µë§Œ ê°ì§€).

### 3. ì„±ë³„ ê°ì§€ (Gender Detection)
ë°œí™”ìì˜ ì„±ë³„ì— ë”°ë¼ ë‹¤ë¥¸ ê¸°ì¤€ ë¶„í¬(Baseline)ë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ í”¼ì¹˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
* **ê¸°ì¤€:** í‰ê·  í”¼ì¹˜(Mean Pitch) **175Hz**
* **ê·¼ê±°:** AI Hub í•œêµ­ì–´ ìŒì„± ë°ì´í„° ëª¨ì§‘ë‹¨ ë¶„í¬ ë¶„ì„ ê²°ê³¼ì— ê¸°ë°˜.
    * `< 175Hz`: **ë‚¨ì„±(Male)** ê¸°ì¤€ ë°ì´í„° ì ìš©
    * `>= 175Hz`: **ì—¬ì„±(Female)** ê¸°ì¤€ ë°ì´í„° ì ìš©

### 4. ì ìˆ˜ ì‚°ì¶œ (Scoring)
* **Z-Score Normalization:** ì¶”ì¶œëœ Raw Dataë¥¼ ì„±ë³„ ê¸°ì¤€ ë¶„í¬(Mean, Std)ë¥¼ ì´ìš©í•´ í‘œì¤€í™”í•©ë‹ˆë‹¤.
* **Weighted Scoring:** ì‚¬ì „ì— ì •ì˜ëœ ê°€ì¤‘ì¹˜(Weights)ë¥¼ ê° ì§€í‘œì— ê³±í•˜ì—¬ ìµœì¢… **ì¢…í•© ì ìˆ˜(Overall)**ì™€ **ê³ ìš© ì¶”ì²œ ì ìˆ˜(Recommended Hiring)**ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.

## ê¸°ë°˜ ì—°êµ¬
ë³¸ ëª¨ë“ˆì˜ ë¶„ì„ ë¡œì§ê³¼ ê°€ì¤‘ì¹˜ëŠ” ë‹¤ìŒ ë…¼ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„ ë° íŠœë‹ë˜ì—ˆìŠµë‹ˆë‹¤.
* Naim, I., Tanveer, M. I., Gildea, D., & Hoque, M. E. (2018). **Automated Analysis and Prediction of Job Interview Performance.** IEEE Transactions on Affective Computing.
